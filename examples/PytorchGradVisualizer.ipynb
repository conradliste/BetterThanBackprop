{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables clear-er\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and dataset\n",
    "import torch\n",
    "import math\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import get_optimizer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "# MNIST Handwriting Dataset\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "batch_size = 64\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Num training batches: {len(trainset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple MLP network for MNIST classification\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_nan_checks(model):\n",
    "    \"\"\"\n",
    "    Registers backward hooks for each parameter in the model\n",
    "\n",
    "    Args:\n",
    "        model (nn.module): model to register hooks for\n",
    "    \"\"\"\n",
    "    def check_grad(module, grad_input, grad_output):\n",
    "        \"\"\"\n",
    "        Checks that if any gradients are NaN during training\n",
    "        \"\"\"\n",
    "        # print(module)\n",
    "        if any(np.all(np.isnan(gi.data.cpu().numpy())) for gi in grad_input if gi is not None):\n",
    "            print('NaN gradient in ' + type(module).__name__)\n",
    "    model.apply(lambda module: module.register_backward_hook(check_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network, hooks, and optimizer\n",
    "import torchvision\n",
    "from collections import deque\n",
    "net = Net()\n",
    "register_nan_checks(net)\n",
    "\n",
    "losses = []\n",
    "epochs = 4\n",
    "avg_grads = []\n",
    "pre_gaus_grads_total = deque() \n",
    "post_gaus_grads_total = deque()\n",
    "biases = deque()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "grad_sum = 0\n",
    "grad_sq_sum = 0\n",
    "num_grads = 0\n",
    "\n",
    "optimizer_name = \"SGD\"\n",
    "optimizer = get_optimizer(f\"{optimizer_name}\", net.parameters())\n",
    "\n",
    "\n",
    "# Train for certain number of epochs\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch:', epoch)\n",
    "    # Loop over the dataset\n",
    "    epoch_loss = 0\n",
    "    # Mini-batch gradient descent\n",
    "    for X, y in trainset:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        grads = np.zeros(8)\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,784))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # For each mini-batch step, get the gradients of the weight matrices\n",
    "        for i, param in enumerate(net.named_parameters()):\n",
    "                name, weight = param\n",
    "                gradient = weight.grad.data\n",
    "                # Store the original and gaussian blurred gradients \n",
    "                if \"weight\" in name:\n",
    "                    pre_gaus_grads_total.append(np.array(gradient.cpu().detach().numpy())) \n",
    "                    gaus_grad = torchvision.transforms.functional.gaussian_blur(gradient.unsqueeze(0), kernel_size=(3,3))\n",
    "                    post_gaus_grads_total.append(gaus_grad.cpu().detach().numpy()) \n",
    "                elif \"bias\" in name:\n",
    "                    biases.append(gradient)\n",
    "    print(\"Loss:\", epoch_loss.item()/len(trainset))\n",
    "    losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the total gaussian blur gradients into layers: np.array[step_num, input_dim, output_dim]\n",
    "pre_gaus_layer1 = []\n",
    "post_gaus_layer1 = []\n",
    "pre_gaus_layer2 = []\n",
    "post_gaus_layer2 = []\n",
    "pre_gaus_layer3 = []\n",
    "post_gaus_layer3 = []\n",
    "pre_gaus_layer4 = []\n",
    "post_gaus_layer4 = []\n",
    "\n",
    "for i in range(len(pre_gaus_grads_total)):\n",
    "    if i % 4 == 0:\n",
    "        pre_gaus_layer1.append(pre_gaus_grads_total[i])\n",
    "        post_gaus_layer1.append(post_gaus_grads_total[i])\n",
    "    elif i % 4 == 1:\n",
    "        pre_gaus_layer2.append(pre_gaus_grads_total[i])\n",
    "        post_gaus_layer2.append(post_gaus_grads_total[i])\n",
    "    elif i % 4 == 2:\n",
    "        pre_gaus_layer3.append(pre_gaus_grads_total[i])\n",
    "        post_gaus_layer3.append(post_gaus_grads_total[i])\n",
    "    else:\n",
    "        pre_gaus_layer4.append(pre_gaus_grads_total[i])\n",
    "        post_gaus_layer4.append(post_gaus_grads_total[i])\n",
    "\n",
    "pre_gaus_layer1 = np.array(pre_gaus_layer1).squeeze()\n",
    "post_gaus_layer1 = np.array(post_gaus_layer1).squeeze()\n",
    "pre_gaus_layer2 = np.array(pre_gaus_layer2).squeeze()\n",
    "post_gaus_layer2 = np.array(post_gaus_layer2).squeeze()\n",
    "pre_gaus_layer3 = np.array(pre_gaus_layer3).squeeze()\n",
    "post_gaus_layer3 = np.array(post_gaus_layer3).squeeze()\n",
    "pre_gaus_layer4 = np.array(pre_gaus_layer4).squeeze()\n",
    "post_gaus_layer4 = np.array(post_gaus_layer4).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_min_max(array, curr_min, curr_max):\n",
    "    r\"\"\"\n",
    "    Compares current minimum and maximum of array with current minimum and maximum\n",
    "\n",
    "    Args:\n",
    "        array(np.array): A numpy array\n",
    "        curr_min (float): The current minimum\n",
    "        curr_max (float): The current maximum\n",
    "    \n",
    "    Returns:\n",
    "        min (float): The minimum value, either curr_min or minimum value of array\n",
    "        max (float): The maximum value, either curr_max or minimum value of array\n",
    "    \"\"\"\n",
    "    if np.max(array) >= curr_max:\n",
    "        curr_max = np.max(array)\n",
    "    if np.min(array) <= curr_min:\n",
    "        curr_min = np.min(array)\n",
    "\n",
    "    return curr_min, curr_max\n",
    "\n",
    "# Calculate min and max grad\n",
    "min_grad, max_grad = grad_min_max(pre_gaus_layer1, 0, 0)\n",
    "min_grad, max_grad = grad_min_max(pre_gaus_layer2, min_grad, max_grad)\n",
    "min_grad, max_grad = grad_min_max(pre_gaus_layer3, min_grad, max_grad)\n",
    "min_grad, max_grad = grad_min_max(pre_gaus_layer4, min_grad, max_grad)\n",
    "print(\"Min Grad:\", min_grad)\n",
    "print(\"Max Grad:\", max_grad)\n",
    "# Calculate average and std grad\n",
    "# avg_grad = grad_sum / num_grads\n",
    "# std_grad = math.sqrt((grad_sq_sum / num_grads) - avg_grad**2)\n",
    "# print(\"Average Grad:\", avg_grad)\n",
    "# print(\"Std Grad:\", std_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Interesting\" Gradients\n",
    "def interesting_gradients(layer, min, max):\n",
    "    r\"\"\"\n",
    "    Returns the indices of \"interesting gradients\" that is not in the range of [min, max]\n",
    "    \n",
    "    Args:\n",
    "        layer ([num_steps, output_dim, input_dim,]): Layer that is passed through to observe \"interesting\" gradients\n",
    "        min (int): Minimum value for \"uninteresting gradients\"\n",
    "        max (int): Maximum value for \"uninteresting gradients\"\n",
    "\n",
    "    Returns:\n",
    "        final (np.array[step_num, output_dim, input_dim]): A 3D array containing all \"interesting dimensions\"\n",
    "    \"\"\"\n",
    "    final = []\n",
    "\n",
    "    wheres = np.concatenate((np.array(np.where(layer > max)), np.array(np.where(layer < min))), axis=1)\n",
    "    \n",
    "    for i in range(wheres[0].size):\n",
    "        final.append(np.array([wheres[0][i], wheres[1][i], wheres[2][i]]))\n",
    "    \n",
    "    if len(final) == 0:\n",
    "        return \"Nothing to see!\"\n",
    "    \n",
    "    return np.array(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the arrays with np.save()\n",
    "saved_grads_dir = \"./grads/\"\n",
    "np.save(saved_grads_dir + f\"{optimizer_name}_layer1\", post_gaus_layer1)\n",
    "np.save(saved_grads_dir + f\"{optimizer_name}_layer2\", post_gaus_layer2)\n",
    "np.save(saved_grads_dir + f\"{optimizer_name}_layer3\", post_gaus_layer3)\n",
    "np.save(saved_grads_dir + f\"{optimizer_name}_layer4\", post_gaus_layer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Gaussian filters... pretty sure it works since the second one looks blurrier\n",
    "import seaborn as sns\n",
    "cur_layer = pre_gaus_layer2\n",
    "gauss_cur_layer = post_gaus_layer2\n",
    "epoch = 900\n",
    "\n",
    "avg_grad = np.average(cur_layer)\n",
    "std_grad = np.std(cur_layer)\n",
    "print(\"Average Grad:\", avg_grad)\n",
    "print(\"Standard Deviation of Grad:\", std_grad)\n",
    "sns.heatmap(data = cur_layer[epoch], vmin=avg_grad-std_grad, vmax=avg_grad+std_grad)\n",
    "plt.show()\n",
    "sns.heatmap(data = gauss_cur_layer[epoch], vmin=avg_grad-std_grad, vmax=avg_grad+std_grad)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the gradients through the steps\n",
    "import os\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/bin/ffmpeg\" # Setting directory for ffmpeg. Must set prior to importing moviepy\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def make_gif(array, save_directory, file_name):\n",
    "    r\"\"\"\n",
    "    Makes a gif from a seaborn heat map\n",
    "\n",
    "    Args:\n",
    "        array (np.array[step_num, output_dim, input_dim]): The layer that will be visualized\n",
    "        save_directory (str): Directory the gif will be placed in\n",
    "        file_name (str): Name of the file\n",
    "    \"\"\"\n",
    "    fps = 60 # Number of frames per second in the gif\n",
    "    duration = array.shape[0] // fps # Duration of the gif in seconds. \n",
    "    fig, ax = plt.subplots()\n",
    "    def make_frame(t):\n",
    "        r\"\"\"\n",
    "        Creates a numpyarray of shape (W x H x 3) that is saved and spliced together in the VideoClip class \n",
    "        Args:\n",
    "            t (int): The time that is being calculated. This is implicitly set in the VideoClip class calculated as: duration / fps * (t)\n",
    "        \"\"\"\n",
    "        plt.clf()\n",
    "        plt.title(f\"Step: {int(t*60)}\")\n",
    "        sns.heatmap(data = array[int(t*60)], vmin = min_grad, vmax = max_grad) # frame number = t*fps\n",
    "        return mplfig_to_npimage(fig)\n",
    "    animation = VideoClip(make_frame, duration=duration) # Calls make_frame() function duration*fps times\n",
    "    animation.write_gif(f\"{save_directory}/{file_name}.gif\", fps=fps) \n",
    "    return\n",
    "\n",
    "for i in range(4):\n",
    "    make_gif(post_gaus_layer1, \"/mnt/c/Users/Jeffrey/Downloads\", \"post_gaus_layer1\")\n",
    "    make_gif(post_gaus_layer2, \"/mnt/c/Users/Jeffrey/Downloads\", \"post_gaus_layer2\")\n",
    "    make_gif(post_gaus_layer3, \"/mnt/c/Users/Jeffrey/Downloads\", \"post_gaus_layer3\")\n",
    "    make_gif(post_gaus_layer4, \"/mnt/c/Users/Jeffrey/Downloads\", \"post_gaus_layer4\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c0f37757b892d71b9ecf8a0fc17159ef45c8ddaa3c79c5e15312c4464e93478"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('TempEnv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
